{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2: Análisis de Opiniones sobre Películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Construcción y descripción del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554\n",
      "3554\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "#train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "#test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "#train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "#test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "\n",
    "ftr = open(\"train_data.csv\", \"r\")\n",
    "fts = open(\"test_data.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "\n",
    "print train_df.shape[0]\n",
    "print test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td></td><td>Train</td><td>Test</td></tr><tr><td>Positivo</td><td>1770</td><td>1751</td></tr><tr><td>Negativo</td><td>1784</td><td>1803</td></tr><tr><td>Total</td><td>3554</td><td>3554</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "n_neg_train = train_df[train_df.Sentiment == -1].count().Sentiment\n",
    "n_pos_train = train_df[train_df.Sentiment == 1].count().Sentiment\n",
    "\n",
    "n_neg_test = test_df[test_df.Sentiment == -1].count().Sentiment\n",
    "n_pos_test = test_df[test_df.Sentiment == 1].count().Sentiment\n",
    "\n",
    "data = [['','Train','Test'],\n",
    "        ['Positivo',n_pos_train,n_pos_test],\n",
    "        ['Negativo',n_neg_train,n_neg_test],\n",
    "        ['Total',n_pos_train+n_neg_train,n_pos_test+n_neg_test]\n",
    "       ]\n",
    "\n",
    "display(HTML(\n",
    "        '<table><tr>{}</tr></table>'.format(\n",
    "            '</tr><tr>'.join(\n",
    "                '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data)\n",
    "        )\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos corresponden a comentarios de películas las cuales pueden tener una etiqueta positiva (+1) o negativa (-1).\n",
    "\n",
    "En total hay 3554 registros de entrenamiento y de prueba. La distribución de los datos según clase se encuentra en la tabla anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Word Extractor: Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def word_extractor_stem(text, stopwords_filter=True):\n",
    "    stemmer = PorterStemmer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ stemmer.stem(word.lower()) \\\n",
    "                  for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if stopwords_filter:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "        \n",
    "    return words\n",
    "\n",
    "def word_extractor(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ word.lower() \\\n",
    "                  for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words+=\" \"+word\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Word Extractor: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extractor_lemm(text, stopwords_filter=True):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) \\\n",
    "                  for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if stopwords_filter:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL\n",
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n",
      "STEMMING\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " n't love eat cake\n",
      "LEMMATIZATION\n",
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n"
     ]
    }
   ],
   "source": [
    "print \"NORMAL\"\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")\n",
    "print \"STEMMING\"\n",
    "print word_extractor_stem(\"I love to eat cake\")\n",
    "print word_extractor_stem(\"I love eating cake\")\n",
    "print word_extractor_stem(\"I loved eating the cake\")\n",
    "print word_extractor_stem(\"I do not love eating cake\")\n",
    "print word_extractor_stem(\"I don't love eating cake\")\n",
    "print \"LEMMATIZATION\"\n",
    "print word_extractor_lemm(\"I love to eat cake\")\n",
    "print word_extractor_lemm(\"I love eating cake\")\n",
    "print word_extractor_lemm(\"I loved eating the cake\")\n",
    "print word_extractor_lemm(\"I do not love eating cake\")\n",
    "print word_extractor_lemm(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En el lenguaje natural, las palabras pueden aparecer en muchas formas: prefijos, sufijos, derivaciones, verbos, etc. El objetivo de las operaciones de Stemming y Lemmatization es normalizar las palabras con el fin de dejarlas en una base común. Lo cual es útil para el procesamiento de texto.\n",
    "\n",
    "Stemming reliza esto mediante heurísticas, donde la base de una palabra no necesariamente tiene significado, pero sí para fines de procesamiento de texto. Porotro lado, Lemmatization lleva todas las palabras a su significado base de la misma forma en que aparece en un diccionario, y por lo tanto es necesario el uso de un diccionario para realizar esta operación. En la mayoría se los casos Stemming se ejecuta en menor tiempo que Lemmatization, debido a su naturaleza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Representación vectorial del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "[(566, u'film'), (481, u'movie'), (246, u'one'), (245, u'like'), (224, u'ha'), (183, u'make'), (176, u'story'), (163, u'character'), (145, u'comedy'), (143, u'time')]\n",
      "Test\n",
      "[(558, u'film'), (540, u'movie'), (250, u'one'), (238, u'ha'), (230, u'like'), (197, u'story'), (175, u'character'), (165, u'time'), (161, u'make'), (134, u'comedy')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor_lemm(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "dist_train=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "dist_test=list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "frec_words_train = []\n",
    "for tag, count in zip(vocab, dist_train):\n",
    "    frec_words_train.append((count, tag))\n",
    "\n",
    "frec_words_test = []\n",
    "for tag, count in zip(vocab, dist_test):\n",
    "    frec_words_test.append((count, tag))\n",
    "\n",
    "print \"Train\"\n",
    "print sorted(frec_words_train, reverse=True)[:10]\n",
    "\n",
    "print \"Test\"\n",
    "print sorted(frec_words_test, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de limpiarlos textos con la operación correspondiente, se genera un vocabulario de las palabras presentes. Las palabras más frecuentes en el conjunto de entreamiento son similares a las del conjunto de prueba, y se detallan, junto con su frecuencia, en la estructura anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Construcción de una función de evaluación de desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas de la función classification_report son la presición, que corresponde a la capacidad del modelo para clasificar correctamente un registro (verdaderos positivos dividido por positivos tanto falsos como verdaderos). recall, que indica el porcentaje de positivos encontrados respecto del total de positivos. y por último F1-score que se calcula en base a los dos anteriores con la siguiente fórmula: $2\\times{\\frac{precision\\times{recall}}{precision + recall}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Clasificador Bayesiano Ingenuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.942881\n",
      "Test Accuracy BernoulliNB: 0.747819\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.92730633  0.07269367] the vintage is pure '87 , with a halfhearted twist on its cautionary message : fatal attraction = do\n",
      "[ 0.00214934  0.99785066] the film aims to be funny , uplifting and moving , sometimes all at once . the extent to which it su\n",
      "[ 0.90653107  0.09346893] it wouldn't be my preferred way of spending 100 minutes or $7 . 00 .\n",
      "\n",
      "[ 0.53477941  0.46522059] rock's stand-up magic wanes . hopkins , squarely fills the screen . action - mechanical .\n",
      "\n",
      "[ 0.00128085  0.99871915] a fascinating documentary about the long and eventful spiritual journey of the guru who helped launc\n"
     ]
    }
   ],
   "source": [
    "#filtro y stem\n",
    "texts_train = [word_extractor_stem(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_stem(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.938098\n",
      "Test Accuracy BernoulliNB: 0.762173\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.77      0.76      0.77      1803\n",
      "          -       0.76      0.76      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n",
      "[ 0.01214587  0.98785413] this engrossing , characteristically complex tom clancy thriller is shifty in the manner in which it\n",
      "[ 0.82000698  0.17999302] fear dot com is more frustrating than a modem that disconnects every 10 seconds .\n",
      "\n",
      "[ 0.05674463  0.94325537] at heart the movie is a deftly wrought suspense yarn whose richer shadings work as coloring rather t\n",
      "[ 0.61268426  0.38731574] a well acted and well intentioned snoozer .\n",
      "\n",
      "[ 0.22515565  0.77484435] . . . a gleefully grungy , hilariously wicked black comedy . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#no filtro y stem\n",
    "texts_train = [word_extractor_stem(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor_stem(text, False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.958638\n",
      "Test Accuracy BernoulliNB: 0.738531\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.24768272  0.75231728] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the wa\n",
      "[ 0.81875336  0.18124664] even fans of ismail merchant's work , i suspect , would have a hard time sitting through this one .\n",
      "\n",
      "[ 0.93871886  0.06128114] it should be interesting , it should be poignant , it turns out to be affected and boring .\n",
      "\n",
      "[ 0.32798024  0.67201976] much like robin williams , death to smoochy has already reached its expiration date .\n",
      "\n",
      "[ 0.99804565  0.00195435] like a medium-grade network sitcom--mostly inoffensive , fitfully amusing , but ultimately so weight\n"
     ]
    }
   ],
   "source": [
    "#filtro y lemm\n",
    "texts_train = [word_extractor_lemm(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.955262\n",
      "Test Accuracy BernoulliNB: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.31602149  0.68397851] the story has little wit and no surprises .\n",
      "\n",
      "[ 0.67888041  0.32111959] borrows a bit from the classics \" wait until dark \" and \" extremities \" . . . but in terms of its st\n",
      "[ 0.99577856  0.00422144] there is more than one joke about putting the toilet seat down . and that should tell you everything\n",
      "[ 0.92211058  0.07788942] the problems of the people in love in the time of money are hardly specific to their era . they just\n",
      "[ 0.65236109  0.34763891] the mark of a respectable summer blockbuster is one of two things : unadulterated thrills or genuine\n"
     ]
    }
   ],
   "source": [
    "#no filtro y lemm\n",
    "texts_train = [word_extractor_lemm(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text, False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores resultados se obtienen al no filtrar los stepwords y utilizar stemming, con un $76\\%$ en los indicadores. Además se obtiene un $76\\%$ también en el error de prueba.\n",
    "\n",
    "Se produce sobreajuste del modelo en todos los casos al tener mayor presición con los datos de entrenamiento.\n",
    "\n",
    "En general los resultados son similares entre sí, entregando una buena clasifcación e indicadores similares, lo cual resulta conveniente ya que al ser el m´todo con stemming sin filtro levemente mejor al resto, al mimso tiempo es el método de limpieza de texto más rápido de ejecutar.\n",
    "\n",
    "Al revisar lo ejemplos aleatorios del texto, en general existe una gran presición al momento de clasificar, aunque de igual manera se distinguen clasificaciones erroneas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g)  Clasificador Bayesiano Ingenuo Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.942600\n",
      "Test Accuracy MULTINOMIAL: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.21161988  0.78838012] shyamalan takes a potentially trite and overused concept ( aliens come to earth ) and infuses it int\n",
      "[ 0.19395967  0.80604033] a little more intensity and a little less charm would have saved this film a world of hurt .\n",
      "\n",
      "[ 0.49791893  0.50208107] it's all surface psychodramatics .\n",
      "\n",
      "[ 0.00309058  0.99690942] informative , intriguing , observant , often touching . . . gives a human face to what's often discu\n",
      "[ 0.63078613  0.36921387] the dangerous lives of altar boys' take on adolescence feels painfully true .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtro y stem\n",
    "texts_train = [word_extractor_stem(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_stem(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.936410\n",
      "Test Accuracy MULTINOMIAL: 0.763580\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.77      0.77      0.77      1803\n",
      "          -       0.76      0.76      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n",
      "[ 0.95149491  0.04850509] the slapstick is labored , and the bigger setpieces flat .\n",
      "\n",
      "[ 0.27440369  0.72559631] pull[s] off the rare trick of recreating not only the look of a certain era , but also the feel .\n",
      "\n",
      "[ 0.00242996  0.99757004] [dong] makes a valiant effort to understand everyone's point of view , and he does such a good job o\n",
      "[ 0.43852889  0.56147111] faithful without being forceful , sad without being shrill , \" a walk to remember \" succeeds through\n",
      "[  8.93282437e-04   9.99106718e-01] it provides a grim , upsetting glimpse at the lives of some of the 1 . 2 million palestinians who li\n"
     ]
    }
   ],
   "source": [
    "#no filtro y stem\n",
    "texts_train = [word_extractor_stem(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor_stem(text, False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.959764\n",
      "Test Accuracy MULTINOMIAL: 0.739375\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.17891285  0.82108715] my wife is an actress works as well as it does because [the leads] are such a companionable couple .\n",
      "[  2.32456925e-04   9.99767543e-01] a poignant and gently humorous parable that loves its characters and communicates something rather b\n",
      "[ 0.93839842  0.06160158] fans of so-bad-they're-good cinema may find some fun in this jumbled mess .\n",
      "\n",
      "[ 0.35152717  0.64847283] what the director can&#8217 ; t do is make either of val kilmer&#8217 ; s two personas interesting o\n",
      "[ 0.95067117  0.04932883] as green-guts monster movies go , it's a beaut .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtro y lemm\n",
    "texts_train = [word_extractor_lemm(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.955824\n",
      "Test Accuracy MULTINOMIAL: 0.752322\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.75      0.75      1803\n",
      "          -       0.75      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.31358182  0.68641818] jacobi , the most fluent of actors , is given relatively dry material from nijinsky's writings to pe\n",
      "[ 0.81119863  0.18880137] no one can doubt the filmmakers' motives , but the guys still feels counterproductive .\n",
      "\n",
      "[ 0.01771374  0.98228626] tadpole is a sophisticated , funny and good-natured treat , slight but a pleasure .\n",
      "\n",
      "[ 0.82298182  0.17701818] one of the worst movies of the year .\n",
      "\n",
      "[ 0.88377624  0.11622376] not at all clear what it's trying to say and even if it were � i doubt it would be all that interest\n"
     ]
    }
   ],
   "source": [
    "#no filtro y lemm\n",
    "texts_train = [word_extractor_lemm(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text, False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente los mejores resultados se obtienen utlizando la técnica de stemming sin filtrar stop words. Los indicadores y el porcentaje de presición son los mismos que el ejercicio anterior, &76\\%& aproximadamente.\n",
    "\n",
    "De la misma forma se produce sobreajuste del modelo en cada caso.\n",
    "\n",
    "En comparación al ejercicio anterior, la utilización de este modelo es levemente mejor que la del modelo anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h) Regresión Logística Regularizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.781373\n",
      "Test Accuracy LOGISTIC: 0.691528\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.69      0.72      0.70      1803\n",
      "          -       0.70      0.66      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.882386\n",
      "Test Accuracy LOGISTIC: 0.728961\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.74      0.73      1803\n",
      "          -       0.73      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.999719\n",
      "Test Accuracy LOGISTIC: 0.724740\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.717703\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.71      0.72      1803\n",
      "          -       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.712356\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.70      0.71      1803\n",
      "          -       0.70      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtro y stem\n",
    "texts_train = [word_extractor_stem(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_stem(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.722566\n",
      "Test Accuracy LOGISTIC: 0.680270\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.69      0.69      1803\n",
      "          -       0.68      0.67      0.67      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.873101\n",
      "Test Accuracy LOGISTIC: 0.728961\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.73      0.73      1803\n",
      "          -       0.73      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.736842\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.72      0.74      1803\n",
      "          -       0.72      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.728680\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.71      0.73      1803\n",
      "          -       0.72      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.721362\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.71      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#no filtro y stem\n",
    "texts_train = [word_extractor_stem(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor_stem(text, False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.787563\n",
      "Test Accuracy LOGISTIC: 0.679144\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.72      0.69      1803\n",
      "          -       0.69      0.64      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.891390\n",
      "Test Accuracy LOGISTIC: 0.718829\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.719674\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.71      0.72      1803\n",
      "          -       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.714044\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.70      0.71      1803\n",
      "          -       0.70      0.73      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.715170\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.71      0.72      1803\n",
      "          -       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtro y lemm\n",
    "texts_train = [word_extractor_lemm(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.721159\n",
      "Test Accuracy LOGISTIC: 0.672390\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.69      0.68      1803\n",
      "          -       0.67      0.66      0.66      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.884074\n",
      "Test Accuracy LOGISTIC: 0.717140\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.725865\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.722207\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.69      0.72      1803\n",
      "          -       0.70      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.720518\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.70      0.75      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#no filtro y lemm\n",
    "texts_train = [word_extractor_lemm(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text, False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera que en resultados anteriores, el mejor resultado se obtiene con la misma limpieza de texto, sin filtro y con stemming. Esta vez los indicadores resultan ser $74\\%$ con un parámetro de regularización de $C=10$.\n",
    "\n",
    "Respecto a las presiciones de entrenamiento y de prueba de manera general, se puede apreciar que el sobre ajuste delos modelos se comporta de manera discreta al saltar de valores de entrenamiento de $100\\%$ a $80\\%$ o $70\\%$. Esto se debe al parámetro de regularización. Más específicamente, con valores pequeños de $C$ el modelo se sobreajusta menos aunque disminuyendo la presicion en el conjunto de prueba, y con valores de $10$ hacia arriba el modelo se sobreajusta enormemente logrando clasificar correctamente la totalida del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) Máquina de Vectores de Soporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.877321\n",
      "Test Accuracy SVM: 0.727273\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.74      0.73      1803\n",
      "          -       0.73      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.981711\n",
      "Test Accuracy SVM: 0.733465\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.73      0.74      1803\n",
      "          -       0.73      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.704475\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.69      0.70      1803\n",
      "          -       0.69      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.699690\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.696594\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.68      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtro y stem\n",
    "texts_train = [word_extractor_stem(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_stem(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.868036\n",
      "Test Accuracy SVM: 0.729243\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.74      0.73      1803\n",
      "          -       0.73      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.983680\n",
      "Test Accuracy SVM: 0.750915\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.715452\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.716015\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.715452\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#no filtro y stem\n",
    "texts_train = [word_extractor_stem(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor_stem(text, False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.888014\n",
      "Test Accuracy SVM: 0.716296\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.721081\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.71      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.702505\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698846\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698283\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtro y lemm\n",
    "texts_train = [word_extractor_lemm(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.879572\n",
      "Test Accuracy SVM: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.988182\n",
      "Test Accuracy SVM: 0.733183\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.72      0.73      1803\n",
      "          -       0.72      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.710667\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.68      0.71      1803\n",
      "          -       0.69      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.707571\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.68      0.70      1803\n",
      "          -       0.69      0.74      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.706727\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.68      0.70      1803\n",
      "          -       0.69      0.74      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#no filtro y lemm\n",
    "texts_train = [word_extractor_lemm(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor_lemm(text, False) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), binary=False)\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es de esperar debido a la tendencia que presenta la naturaleza de los datos la limpieza óptima del texto es sin filtrar y con stemming. Se presenta un valor de $75\\%$ en todos los indicadores y de igual manera para la presición del conjunto de prueba. De igual manera el sobre ajuste es claro para valores de $C$ superiores a 10 y disminuye drásticamente con valores pequeños. En esta ocasión el valor de regularización óptimo es de $0.1$ para el que se entrena el mejor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## j) Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td></td><td>Bernoulli Naive</td><td>Multinomial Naive</td><td>Logistic Regression</td><td>Linear SVM</td></tr><tr><td>Metodo Limpieza Texto</td><td>Sin filtrar stopwords y Stemming</td><td>Sin filtrar stopwords y Stemming</td><td>Sin filtrar stopwords y Stemming</td><td>Sin filtrar stopwords y Stemming</td></tr><tr><td>Parametro Regularizacion</td><td>-</td><td>-</td><td>C=10</td><td>C=0.1</td></tr><tr><td>Test Accuracy</td><td>76.2173%</td><td>76.3580%</td><td>73.6842%</td><td>75.0915%</td></tr><tr><td>Precision</td><td>76%</td><td>76%</td><td>74%</td><td>75%</td></tr><tr><td>Recall</td><td>76%</td><td>76%</td><td>74%</td><td>75%</td></tr><tr><td>F1-Score</td><td>76%</td><td>76%</td><td>74%</td><td>75%</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [['','Bernoulli Naive','Multinomial Naive','Logistic Regression','Linear SVM'],\n",
    "        ['Metodo Limpieza Texto','Sin filtrar stopwords y Stemming','Sin filtrar stopwords y Stemming','Sin filtrar stopwords y Stemming','Sin filtrar stopwords y Stemming'],\n",
    "        ['Parametro Regularizacion','-','-','C=10','C=0.1'],\n",
    "        ['Test Accuracy','76.2173%','76.3580%','73.6842%','75.0915%'],\n",
    "        ['Precision','76%','76%','74%','75%'],\n",
    "        ['Recall','76%','76%','74%','75%'],\n",
    "        ['F1-Score','76%','76%','74%','75%']\n",
    "       ]\n",
    "\n",
    "display(HTML(\n",
    "        '<table><tr>{}</tr></table>'.format(\n",
    "            '</tr><tr>'.join(\n",
    "                '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data)\n",
    "        )\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2P8HCeEIMqS/GqsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131b4ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "models_tags = [\"BN\", \"MN\", \"LR\", \"SVM\"]\n",
    "perc = [76.2173, 76.3580, 73.6842, 75.0915]\n",
    "plt.xticks(range(4), models_tags)\n",
    "ax.plot(range(4), perc)\n",
    "plt.ylabel(\"precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información relevante corresponde a los indicadores entregados con la función de evaluación de los modelos y la presición de prueba, cada uno para cada modelo en su configuración óptima según los resultados obtenidos.\n",
    "\n",
    "La tabla anterior muestra un resumen de todo el trabajo realizado y los mejores resultados obtenidos. El gráfico muestra una comparación de los porcentajes de precisión de cada modelo.\n",
    "\n",
    "Finalmente, Multinomial Naive es el modelo que mejores resultados presenta para el conjunto de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
